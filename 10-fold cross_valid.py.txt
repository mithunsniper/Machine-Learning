import struct
import numpy as np
import matplotlib.pyplot as plt
import random
import math
import operator
from numpy import float64
from random import shuffle



def read_idx(filename):
    with open(filename, 'rb') as f:
        zero,data_type,dims=struct.unpack('>HBB',f.read(4))
        shape=tuple(struct.unpack('>I',f.read(4))[0] for d in range(dims))
        return np.fromstring(f.read(),dtype=np.uint8).reshape(shape)

raw_train=read_idx("train-images.idx3-ubyte")
train_data=np.reshape(raw_train,(60000,28*28))

train_label=read_idx("train-labels.idx1-ubyte")


raw_test=read_idx("t10k-images.idx3-ubyte")
test_data=np.reshape(raw_test,(10000,28*28))


test_label=read_idx("t10k-labels.idx1-ubyte")



train_data=np.array(train_data,dtype=float64)
test_data=np.array(test_data,dtype=float64)



def euclideanDistance(instance1, instance2, length):
	distance = 0
 	for x in range(length):
 		distance += pow((instance1[x] - instance2[x]), 2)
	return math.sqrt(distance)



def getNeighbors(trainingSet, testInstance, k,train_label):
	distances =[]

	length = len(testInstance)-1
	for x in range(int(len(trainingSet))):
		dist = euclideanDistance(testInstance, trainingSet[x], length)
		distances.append((trainingSet[x],train_label[x], dist))
	distances.sort(key=operator.itemgetter(2))
	
	neighbors =[]

	for x in range(k):
			
		neighbors.append(distances[x][1])
	neighbors=np.array(neighbors)
	neighbors=np.reshape(neighbors,(k,1))
	
	return neighbors


def findKnearest(countneighbours):
	return sorted(countneighbours.items(), key=operator.itemgetter(1), reverse=True)


def find_majority(neighbors):
	
	countneighbours ={}

	for m in range(len(neighbors)):

		value =neighbors[m,:]
		print(value)

		if value in tuple(countneighbours):
			countneighbours[tuple(value)] += 1
		else:
			countneighbours[tuple(value)] = 1
			print(countneighbours)

		total = findKnearest(countneighbours)
	
	return total[0][0]



def knn_class(train_data,test_data,train_label,test_label):

	k=[1,2,3,4,5,6,7,8,9,10]

	for i in k:
		correct_v = 0
		for x in range(int(len(test_data))):
			neighbors =np.array(getNeighbors(train_data,test_data[x], k[i-1],train_label))

			label_pred=find_majority(neighbors)
			if label_pred==test_label[x]:
				correct_v +=1


		accuracy=correct_v/(int(len(test_data)))
		print(accuracy*100)



#SHUFFLING OF TRAINING DATASETS
a=[i for i in range(0,60000)]
shuffle(a)

train_s=np.array(train_data[a])
label_s=np.array(train_label[a])

#K-FOLD CROSS VALIDATION

for i in range(10):
	test_kfold =train_s[(i*6000):(6000 * (i + 1)), :]
	label_s=np.reshape(label_s,(60000,1))
	test_kfoldlbl =label_s[(i*6000):(6000*(i + 1)), :]
	train_kfold = np.empty((1200,784))
	train_kfoldlbl = np.empty((1200,1))


	for j in range(10):
		if(j!=i):
			temp=train_s[(j * 6000):(6000*(j+1)),:]

			templbl=label_s[(j * 6000):(6000*(j+1)),:]

			train_kfold = np.append(train_kfold,temp, 0)

			train_kfoldlbl=np.append(train_kfoldlbl,templbl, 0)
	train_kfold = train_kfold[1200:12000,:]
	train_kfoldlbl = train_kfoldlbl[1200:12000, :]
	
	knn_class(train_kfold,test_kfold,train_kfoldlbl,test_kfoldlbl)







